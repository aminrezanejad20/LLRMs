# LLRMs
Recently, Large Language Models (LLMs) have inspired a lively field of applications due to their amazing adeptness in understanding and generating natural languages. However, while paying attention to new and emerging opportunities from their wide appeal in various services, it is necessary to consider new and unknown threats in this new territory. According to the report of OWASP Foundation, Prompt Injection attack is in the first place of the risks related to large language models, and in this field, studies are being conducted recently, and there is still no suitable approach and solution to benefit from the capabilities of Large Language Models and It is not provided away from vulnerabilities and threats. In this research, while analyzing the complexities and consequences of Prompt Injection Cyber Attacks in independent LLMs and programs integrated with LLMs, we will express an approach to improve the security of chatbots based on Large Language Models with the aim of monitoring threats and anticipating attacks. And we hope that on the eve of the era of large language models, our approach will inspire further research to develop stronger defenses against dangerous threats such as Prompt Injection Attacks.
